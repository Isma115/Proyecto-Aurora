#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Proyecto Aurora - Chatbot con Gemma 2 2B, RAG y Memoria a Largo Plazo
=====================================================================

Punto de entrada principal de la aplicaci√≥n.
El modelo se descarga autom√°ticamente en la primera ejecuci√≥n.

Caracter√≠sticas:
- LLM: Gemma 2 2B (modelo local, sin servidor)
- RAG: B√∫squeda de contexto en archivos .txt (umbral 60%)
- Memoria: Res√∫menes autom√°ticos cada 4 mensajes
- UI: Interfaz moderna con tkinter

Uso:
    python chatbot.py

Requisitos:
    pip install llama-cpp-python
"""

import sys
import os

# A√±adir directorio actual al path
sys.path.insert(0, os.path.dirname(os.path.abspath(__file__)))


def check_dependencies():
    """Verifica que las dependencias est√©n instaladas"""
    missing = []
    
    try:
        import requests
    except ImportError:
        # requests no es estrictamente necesario con el nuevo c√≥digo
        pass
    
    try:
        from llama_cpp import Llama
    except ImportError:
        missing.append("llama-cpp-python")
    
    if missing:
        print("=" * 50)
        print("‚ùå Faltan dependencias:")
        print()
        for dep in missing:
            print(f"   - {dep}")
        print()
        print("Inst√°lalas con:")
        print(f"   pip install {' '.join(missing)}")
        print("=" * 50)
        return False
    
    return True


def main():
    """Funci√≥n principal"""
    print("=" * 50)
    print("üåå Proyecto Aurora - Local")
    print("   RAG & Memoria a Largo Plazo")
    print("=" * 50)
    
    # Verificar dependencias
    print("\nüì¶ Verificando dependencias...")
    if not check_dependencies():
        print("\n‚õî No se puede iniciar sin las dependencias.")
        input("Presiona Enter para salir...")
        sys.exit(1)
    
    print("‚úÖ Dependencias OK")
    
    # Importar m√≥dulos
    from chat_engine import ChatEngine
    from ui_components import ChatWindow
    
    # Inicializar el motor de chat
    print("\nüîß Creando motor de chat...")
    chat_engine = ChatEngine()
    
    # Mostrar estad√≠sticas RAG
    stats = chat_engine.get_stats()
    print(f"\nüìä Base de conocimiento:")
    print(f"   - Documentos: {stats['rag']['documents']}")
    print(f"   - Fragmentos: {stats['rag']['chunks']}")
    
    # Iniciar interfaz gr√°fica
    print("\nüöÄ Iniciando interfaz gr√°fica...")
    print("   (El modelo se descargar√° autom√°ticamente si es necesario)")
    
    app = ChatWindow(chat_engine)
    app.mainloop()


if __name__ == "__main__":
    main()
